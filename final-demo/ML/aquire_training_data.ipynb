{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!pip install pysolr\n",
    "#!pip install textblob\n",
    "\n",
    "import pysolr\n",
    "import pandas as pd\n",
    "from __future__ import division, unicode_literals \n",
    "import math\n",
    "from textblob import TextBlob as tb\n",
    "\n",
    "import json\n",
    "import requests\n",
    "from datetime import datetime, date, time\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#super categories\n",
    "# each super category is a list of node-ids\n",
    "\n",
    "super_cat1 = [2950,3179,3188,3214,3263,3939,171114,465288,132561011,377550011,6133990011,6343223011,7976022011,8622832011,10806600011]\n",
    "\n",
    "super_cat2 = [ 2672,2946,3122,3131,3167,3185,3200,3215,3262,3279,3610,3612,3616,3981,3987,4134,4676,5322,13682,688868,720028,882340,13998731,15375251,16244041,16244061,713347011,3564978011,3564986011,7009088011,8883852011,8883853011,8883961011,8951155011,8951160011,8951165011,8951173011,8951174011,8951191011 ]\n",
    "\n",
    "super_cat3 = [1002,1007,2963,3094,3291,3527,4263,4278,282838,8883838011,8951153011,9432890011,9432902011 ]\n",
    "\n",
    "super_cat4 = [2945, 3220, 4296, 282840, 8883864011, 8883963011, 8944264011, 9432900011]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#################################\n",
    "# wrapper functions\n",
    "#################################\n",
    "\n",
    "def solrWrap(core,params):\n",
    "    query_string='http://localhost:8983/solr/'+core+'/select?'\n",
    "    for key in params:\n",
    "        query_string=query_string+key+'='+params[key]+'&'\n",
    "        #print (query_string)\n",
    "    solrcon = pysolr.Solr(query_string, timeout=10)\n",
    "    results = solrcon.search('*:*')\n",
    "    docs=pd.DataFrame(results.docs)\n",
    "    \n",
    "    return docs\n",
    "    \n",
    "def asterixDBWrapper(dverse, query):\n",
    "    statement = 'USE '+dverse+';'+query\n",
    "    payload = {'statement': statement}\n",
    "    a_response = requests.post('http://132.249.238.32:19002/query/service', data = payload)\n",
    "    print \"---------\\n\"\n",
    "    print (a_response.status_code)\n",
    "    print (a_response)\n",
    "    print \"---------\\n\"\n",
    "    q = a_response.json()\n",
    "    #print q\n",
    "    \n",
    "    return pd.DataFrame(q['results'])\n",
    "    \n",
    "\n",
    "def postgresWrapper(qr):\n",
    "    url = 'postgresql://student:123456@132.249.238.27:5432/bookstore_dp'\n",
    "    #def connect(self):\n",
    "    print (\"url:\" + url)\n",
    "    engine = create_engine(url)    \n",
    "#def get_dataframe(self,datalog=None,query=None):\n",
    "\n",
    "    df = pd.read_sql(qr, engine)\n",
    "    engine.dispose()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#################################\n",
    "# Function to extract reviews from Asterix DB for a given list of ASINs\n",
    "#################################\n",
    "def extract_reviews_from_asterix(asin_list):\n",
    "    print(\"Extracting reviews from Asterix DB\")\n",
    "    #convert the list of ASINs to string\n",
    "    st = str(asin_list).strip('[]')\n",
    "    dverse ='bookstore_dp'\n",
    "    #query =\"SELECT VALUE r FROM reviews r WHERE asin in [%s];\"%st\n",
    "    query = \"\"\"SELECT  r.asin as asin, get_month(datetime_from_unix_time_in_secs(bigint(r.unixReviewTime)))  as mon, \n",
    "      get_year(datetime_from_unix_time_in_secs(bigint(r.unixReviewTime))) as yr, r.reviewText as reviewtext,\n",
    "      float(r.overall) as review_rating \n",
    "       FROM  reviews r \n",
    "       WHERE asin in [%s]; \"\"\"%(st)\n",
    "    statement = 'USE '+dverse+';'+query\n",
    "    #print(statement)\n",
    "    d2 = asterixDBWrapper(dverse, query)\n",
    "    return d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#function to extract sales features from ML view in postgres\n",
    "def extract_ml_features_from_pgdb(category_list):\n",
    "    print (\"extracting ml features from pgdb\")\n",
    "    st = str(category_list).strip('[u]')\n",
    "    #q = \"SELECT * FROM mv_mlview WHERE nodeid in ( \"+ str(category_list).strip('[]')+\" )\"\n",
    "    q = \"SELECT * FROM mv_mlview WHERE nodeid in ( %s )\"%(st)\n",
    "    df = postgresWrapper(q)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#function to extract nodeids and asin values from postgres\n",
    "def extract_asin_pgdb(category_list):\n",
    "    print (\"extracting ASINs from pgdb\")\n",
    "    #convert list of integers to list of strings as nodeid is string in pgdb\n",
    "    cat = [str(i) for i in category_list]\n",
    "    st = str(cat).strip('[]')\n",
    "    #build query to extract node-id and asin\n",
    "    q = \"\"\"SELECT CAST(p.nodeid as FLOAT), p.asin\n",
    "           FROM products p\n",
    "           WHERE p.nodeid in ( %s ) \n",
    "           ORDER BY p.nodeid \"\"\"%(st)\n",
    "    df = postgresWrapper(q)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculating sentiment polarity, the values ranges from -1 to 1\n",
    "def compute_sentimental_polarity(r_text):\n",
    "    str1 = str(r_text).encode('ascii')\n",
    "    blob=tb(str1)\n",
    "    return blob.sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 5.01 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#function append columns with sentimental polarity and review count\n",
    "def append_sentip_columns(df):\n",
    "    print (\"Computing sentimental polarity\")\n",
    "    df1= df.copy()\n",
    "    df1[\"senti_polarity\"] = [compute_sentimental_polarity(df1.loc[idx, 'reviewtext']) for idx in range(len(df1))]\n",
    "    df1[\"review_count\"] = 1\n",
    "    #drop the reviewtext column with raw review texts after we compute sentimental polarity\n",
    "    df1 = df1.drop('reviewtext', 1)\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to aggregate on nodeId after computing sentimental polarity \n",
    "def agg_review_data(df):\n",
    "    # list of ML features related to review count/rating and sentimental polarity\n",
    "    col = ['pm_reviews', 'p3m_reviews', 'p12m_reviews','pm_avgrating', 'p3m_avgrating', 'p12m_avgrating', 'pm_sentip', 'p3m_sentip', 'p12m_sentip' ]\n",
    "    aggr_map = {'senti_polarity':['mean'], 'review_rating':['mean'], 'review_count':['sum']}    #aggregator\n",
    "    dfs=df.groupby(['nodeid', 'yr', 'mon'],as_index=False).agg(aggr_map)\n",
    "    dfs['nodeid'] = pd.to_numeric(dfs['nodeid'], errors='coerce')\n",
    "    #drop to single column index   \n",
    "    dfs.columns = dfs.columns.droplevel(level=1)\n",
    "    #add ml columns and initialize them to zero\n",
    "    for l in col:\n",
    "        dfs[l] = 0.0\n",
    "    return dfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to compute pm, p3m and p12m values for review count, rating and sentimental polarity\n",
    "def compute_pm_values(df):\n",
    "    df2 = df.copy()\n",
    "    #populate previous month columns for reviews, rating and sentimental polarity\n",
    "    for i in range(1, (len(df2))):\n",
    "        df2.loc[i, 'pm_reviews'] = df2.loc[i-1, 'review_count']\n",
    "        df2.loc[i, 'pm_avgrating'] = df2.loc[i-1, 'review_rating']\n",
    "        df2.loc[i, 'pm_sentip'] = df2.loc[i-1, 'senti_polarity']\n",
    "\n",
    "    #cmpute the averag of prev 3 months for reviews, rating and sentimental polarity\n",
    "    for i in range(3, (len(df2))):\n",
    "        val=0\n",
    "        val1 = 0\n",
    "        val2=0\n",
    "        for j in range(1,4):\n",
    "            val = val + df2.loc[i-j, 'review_rating']\n",
    "            val1 = val1 + df2.loc[i-j, 'review_count']\n",
    "            val2 = val2 + df2.loc[i-j, 'senti_polarity']\n",
    "        df2.loc[i, 'p3m_avgrating'] = val/3.0\n",
    "        df2.loc[i, 'p3m_reviews'] = val1\n",
    "        df2.loc[i, 'p3m_sentip'] = val2/3.0\n",
    "\n",
    "    #cmpute the averag of prev 12 months for reviews, rating and sentimental polarity\n",
    "    for i in range(12, (len(df2))):\n",
    "        val=0\n",
    "        val1 = 0\n",
    "        val2=0\n",
    "        for j in range(1,13):\n",
    "            val = val + df2.loc[i-j, 'review_rating']\n",
    "            val1 = val1 + df2.loc[i-j, 'review_count']\n",
    "            val2 = val2 + df2.loc[i-j, 'senti_polarity']\n",
    "        df2.loc[i, 'p12m_avgrating'] = val/12.0\n",
    "        df2.loc[i, 'p12m_reviews'] = val1\n",
    "        df2.loc[i, 'p12m_sentip'] = val2/12.0\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Function to compute pm, p3m and p12m values for review count, rating and sentimental polarity for a list of node-ids\n",
    "def populate_pm_columns(df, cat_list):\n",
    "    #build a dataframe that icludes all months/years\n",
    "    print(\"Computing ML review features\")\n",
    "    rg = pd.date_range(str(df['yr'].min()), str(df['yr'].max()+1), freq=\"M\")\n",
    "    df_base = pd.DataFrame(rg, columns=['dt'])\n",
    "    df_base['yr'] = df_base['dt'].dt.year\n",
    "    df_base['mon'] = df_base['dt'].dt.month\n",
    "    df_base = df_base.drop('dt', 1)\n",
    "    for idx, val in enumerate(cat_list):    \n",
    "        df2 = pd.merge(df_base, df[df.nodeid == val], on=['yr', 'mon'], how='left').fillna(0).astype(float)\n",
    "        df3 = compute_pm_values(df2)\n",
    "        df3.loc[(df3.iloc[:, 6:9] != 0).any(1), 'nodeid'] = val\n",
    "        if idx == 0:\n",
    "            #print df2.head(20)\n",
    "            df_final= df3.copy()\n",
    "        else:\n",
    "            df_final = pd.concat([df_final, df3], ignore_index=True)\n",
    "#         print idx, val\n",
    "#         print df2.shape\n",
    "#         print df3.shape\n",
    "#         print df_final.shape\n",
    "    return df_final\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#function to extract review text and rating info from postgres\n",
    "def extract_reviews_from_pgdb(category_list):\n",
    "    print(\"Extracting reviews from pgdb\")\n",
    "    #convert list of integers to list of strings as nodeid is string in pgdb\n",
    "    cat = [str(i) for i in category_list]\n",
    "    st = str(cat).strip('[]')\n",
    "    #get review text for sentimental analysis\n",
    "    q = \"\"\"SELECT p.nodeid, p.asin, c.month as mon, c.year as yr, r.reviewtext, r.overall as review_rating \n",
    "           FROM products p, calendar c, reviews r \n",
    "           WHERE r.reviewtime = c.date AND p.asin = r.asin AND p.nodeid in ( %s \n",
    "           ) ORDER BY p.nodeid,  c.year, c.month \"\"\"%(st)\n",
    "    df = postgresWrapper(q)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Function to extract ML review features from postgres db\n",
    "def extract_ml_review_features_from_pgdb(cat_list):\n",
    "    print (\"Extracting ML review features from pgdb\")\n",
    "    #extract the reviews from postgres db\n",
    "    df1 = extract_reviews_from_pgdb(cat_list)\n",
    "    #convert the text into sentimental polarity\n",
    "    df2 = append_sentip_columns(df1)\n",
    "    \n",
    "    #append the ml feature columns (prev month, prev 3months etc) and aggregate the data on nodeid\n",
    "    df3 = agg_review_data(df2)\n",
    "    #populate ml feature columns\n",
    "    df4 = populate_pm_columns(df3, cat_list)\n",
    "    df5 = df4[df4.nodeid != 0].sort_values(['nodeid', 'yr', 'mon'], ascending=[True, True, True]).reset_index(drop=True)\n",
    "    return df5\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Function to extract ML review features from Asterix db\n",
    "def extract_ml_review_features_from_asterix(cat_list):\n",
    "    print (\"Extracting ML review features from Asterix\")\n",
    "    #first get the asin's for the categories from postgres db\n",
    "    df1= extract_asin_pgdb(super_cat1)\n",
    "    #print df1.head()\n",
    "    #get the ASIN list to pass to asterix\n",
    "    asinlist = df1['asin'].astype(str).tolist()\n",
    "    df2 = extract_reviews_from_asterix(asinlist)\n",
    "    df3 = pd.merge(df1, df2, on= ['asin']).sort_values(['nodeid'], ascending=[True]).fillna(0)\n",
    "    #convert the text into sentimental polarity\n",
    "    df4 = append_sentip_columns(df3)\n",
    "    \n",
    "    #append the ml feature columns (prev month, prev 3months etc) and aggregate the data on nodeid\n",
    "    df5 = agg_review_data(df4)\n",
    "    #populate ml feature columns\n",
    "    df6 = populate_pm_columns(df5, cat_list)\n",
    "    df7 = df6[df6.nodeid != 0].sort_values(['nodeid', 'yr', 'mon'], ascending=[True, True, True]).reset_index(drop=True)\n",
    "    return df7 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Function to extract ML features from postgres and review ml features from asterix\n",
    "def extract_ml_features_multisource(cat_list):\n",
    "    print (\"Extracting ML features from Multisource\")\n",
    "\n",
    "    #extract the ml feature list from pdgb\n",
    "    pgd1= extract_ml_features_from_pgdb(cat_list)\n",
    "    \n",
    "    #extract the ml feature list from asterix\n",
    "    asd1 = extract_ml_review_features_from_asterix(cat_list)\n",
    "    \n",
    "    #merge the data\n",
    "    df_sc = pd.merge(pgd1, asd1, on= ['yr', 'mon','nodeid'], how='left').sort_values(['nodeid', 'yr', 'mon'], ascending=[True, True, True]).fillna(0)\n",
    "    return df_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Function to extract ML features and review features from single source(pgdb)\n",
    "def extract_ml_features_singlesource(cat_list):\n",
    "    print (\"Extracting ML features from Single source\")\n",
    "\n",
    "    #extract the ml feature list from pdgb\n",
    "    pgd1= extract_ml_features_from_pgdb(cat_list)\n",
    "    \n",
    "    #extract the ml feature list from asterix\n",
    "    pgd2 = extract_ml_review_features_from_pgdb(cat_list)\n",
    "    \n",
    "    #merge the data\n",
    "    df_sc = pd.merge(pgd1, pgd2, on= ['yr', 'mon','nodeid'], how='left').sort_values(['nodeid', 'yr', 'mon'], ascending=[True, True, True]).fillna(0)\n",
    "    return df_sc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to extract ML features for given month and year and a list of node-ids for prediction task\n",
    "def extract_ml_features_multisource_for_month(category_list, month, year):\n",
    "    sdf = extract_ml_features_multisource(category_list)\n",
    "    sdf2 = sdf[(sdf.yr == year) & (sdf.mon == month)]\n",
    "    return sdf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ML features from Multisource\n",
      "extracting ml features from pgdb\n",
      "url:postgresql://student:123456@132.249.238.27:5432/bookstore_dp\n",
      "Extracting ML review features from Asterix\n",
      "extracting ASINs from pgdb\n",
      "url:postgresql://student:123456@132.249.238.27:5432/bookstore_dp\n",
      "Extracting reviews from Asterix DB\n",
      "---------\n",
      "\n",
      "200\n",
      "<Response [200]>\n",
      "---------\n",
      "\n",
      "Computing sentimental polarity\n",
      "Computing ML review features\n",
      "CPU times: user 614 ms, sys: 38.1 ms, total: 652 ms\n",
      "Wall time: 9.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cat = [4134]\n",
    "year = 2014\n",
    "month = 7\n",
    "sdf = extract_ml_features_multisource_for_month(cat, month, year)\n",
    "sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ML features from Single source\n",
      "extracting ml features from pgdb\n",
      "url:postgresql://student:123456@132.249.238.27:5432/bookstore_dp\n",
      "Extracting ML review features from pgdb\n",
      "Extracting reviews from pgdb\n",
      "url:postgresql://student:123456@132.249.238.27:5432/bookstore_dp\n",
      "Computing sentimental polarity\n",
      "Computing ML review features\n",
      "(485, 31)\n",
      "CPU times: user 6.45 s, sys: 47 ms, total: 6.5 s\n",
      "Wall time: 8.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### Extract features for training task (use single source for both sales and reviews)\n",
    "df1= extract_ml_features_singlesource(super_cat1)\n",
    "print df1.shape\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# sdf1= extract_ml_features_multisource(super_cat1)\n",
    "# # sdf2= extract_ml_features_multisource(super_cat2)\n",
    "# # sdf3= extract_ml_features_multisource(super_cat3)\n",
    "# # sdf4= extract_ml_features_multisource(super_cat4)\n",
    "\n",
    "# # print sdf1.shape, sdf2.shape, sdf3.shape, sdf4.shape\n",
    "# sdf1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ML features from Multisource\n",
      "extracting ml features from pgdb\n",
      "url:postgresql://student:123456@132.249.238.27:5432/bookstore_dp\n",
      "Extracting ML review features from Asterix\n",
      "extracting ASINs from pgdb\n",
      "url:postgresql://student:123456@132.249.238.27:5432/bookstore_dp\n",
      "Extracting reviews from Asterix DB\n",
      "---------\n",
      "\n",
      "200\n",
      "<Response [200]>\n",
      "---------\n",
      "\n",
      "Computing sentimental polarity\n",
      "Computing ML review features\n",
      "Extracting ML features from Multisource\n",
      "extracting ml features from pgdb\n",
      "url:postgresql://student:123456@132.249.238.27:5432/bookstore_dp\n",
      "Extracting ML review features from Asterix\n",
      "extracting ASINs from pgdb\n",
      "url:postgresql://student:123456@132.249.238.27:5432/bookstore_dp\n",
      "Extracting reviews from Asterix DB\n",
      "---------\n",
      "\n",
      "200\n",
      "<Response [200]>\n",
      "---------\n",
      "\n",
      "Computing sentimental polarity\n",
      "Computing ML review features\n",
      "Extracting ML features from Multisource\n",
      "extracting ml features from pgdb\n",
      "url:postgresql://student:123456@132.249.238.27:5432/bookstore_dp\n",
      "Extracting ML review features from Asterix\n",
      "extracting ASINs from pgdb\n",
      "url:postgresql://student:123456@132.249.238.27:5432/bookstore_dp\n",
      "Extracting reviews from Asterix DB\n",
      "---------\n",
      "\n",
      "200\n",
      "<Response [200]>\n",
      "---------\n",
      "\n",
      "Computing sentimental polarity\n",
      "Computing ML review features\n",
      "Extracting ML features from Multisource\n",
      "extracting ml features from pgdb\n",
      "url:postgresql://student:123456@132.249.238.27:5432/bookstore_dp\n",
      "Extracting ML review features from Asterix\n",
      "extracting ASINs from pgdb\n",
      "url:postgresql://student:123456@132.249.238.27:5432/bookstore_dp\n",
      "Extracting reviews from Asterix DB\n",
      "---------\n",
      "\n",
      "200\n",
      "<Response [200]>\n",
      "---------\n",
      "\n",
      "Computing sentimental polarity\n",
      "Computing ML review features\n",
      "(485, 31) (1553, 31) (436, 31) (247, 31)\n",
      "CPU times: user 31.5 s, sys: 224 ms, total: 31.7 s\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sdf1= extract_ml_features_multisource(super_cat1)\n",
    "sdf2= extract_ml_features_multisource(super_cat2)\n",
    "sdf3= extract_ml_features_multisource(super_cat3)\n",
    "sdf4= extract_ml_features_multisource(super_cat4)\n",
    "\n",
    "print sdf1.shape, sdf2.shape, sdf3.shape, sdf4.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col = sdf1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'nodeid', u'yr', u'mon', u'total_sales_volume', u'total_sales_price',\n",
       "       u'pm_total_sales_volume', u'pm_total_sales_price',\n",
       "       u'l3m_total_sales_volume', u'l3m_total_sales_price',\n",
       "       u'l12m_total_sales_volume', u'l12m_total_sales_price', u'pm_numreviews',\n",
       "       u'pm_avgrating_x', u'l3m_numreviews', u'l3m_avgrating',\n",
       "       u'l12m_numreviews', u'l12m_avgrating', u'numreviews', u'avgrating',\n",
       "       u'review_rating', u'review_count', u'senti_polarity', u'pm_reviews',\n",
       "       u'p3m_reviews', u'p12m_reviews', u'pm_avgrating_y', u'p3m_avgrating',\n",
       "       u'p12m_avgrating', u'pm_sentip', u'p3m_sentip', u'p12m_sentip'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Drop the duplicate columns related to review rating and count info\n",
    "drop_col = [u'pm_reviews',u'p3m_reviews', u'p12m_reviews', u'pm_avgrating_y', u'p3m_avgrating', u'p12m_avgrating']\n",
    "sdf1a = sdf1.drop(drop_col, axis=1)\n",
    "sdf2a = sdf2.drop(drop_col, axis=1)\n",
    "sdf3a = sdf3.drop(drop_col, axis=1)\n",
    "sdf4a = sdf4.drop(drop_col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'nodeid', u'yr', u'mon', u'total_sales_volume', u'total_sales_price',\n",
       "       u'pm_total_sales_volume', u'pm_total_sales_price',\n",
       "       u'l3m_total_sales_volume', u'l3m_total_sales_price',\n",
       "       u'l12m_total_sales_volume', u'l12m_total_sales_price', u'pm_numreviews',\n",
       "       u'pm_avgrating_x', u'l3m_numreviews', u'l3m_avgrating',\n",
       "       u'l12m_numreviews', u'l12m_avgrating', u'numreviews', u'avgrating',\n",
       "       u'review_rating', u'review_count', u'senti_polarity', u'pm_sentip',\n",
       "       u'p3m_sentip', u'p12m_sentip'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf1a.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/skenchar/Documents/DSE/skenchar/DSE203/src/dse203-demand-pred/query-code\n",
      "total 2472\n",
      "drwxr-xr-x  29 skenchar  staff     928 Dec  2 17:51 \u001b[34m.\u001b[m\u001b[m\n",
      "drwxr-xr-x   9 skenchar  staff     288 Nov 29 22:12 \u001b[34m..\u001b[m\u001b[m\n",
      "-rw-r--r--@  1 skenchar  staff    6148 Dec  2 17:51 .DS_Store\n",
      "drwxr-xr-x   8 skenchar  staff     256 Dec  2 17:38 \u001b[34m.ipynb_checkpoints\u001b[m\u001b[m\n",
      "-rw-r--r--   1 skenchar  staff    3593 Nov 29 22:12 DSE-203-Postgres.ipynb\n",
      "-rw-r--r--   1 skenchar  staff   39009 Nov 29 22:12 Demo Direct API and Simple Flask REST Calls.ipynb\n",
      "-rw-r--r--   1 skenchar  staff    6545 Nov 29 22:12 Demo Simple Wrapper Calls.ipynb\n",
      "-rw-r--r--   1 skenchar  staff   80951 Nov 29 22:12 Direct API and Simple Flask REST Calls.ipynb\n",
      "-rw-r--r--   1 skenchar  staff   47000 Dec  1 13:43 ML_feat_cat1.csv\n",
      "-rw-r--r--   1 skenchar  staff  149714 Dec  1 13:43 ML_feat_cat2.csv\n",
      "-rw-r--r--   1 skenchar  staff   42257 Dec  1 13:43 ML_feat_cat3.csv\n",
      "-rw-r--r--   1 skenchar  staff   23846 Dec  1 13:43 ML_feat_cat4.csv\n",
      "-rw-r--r--   1 skenchar  staff   60351 Dec  2 17:51 ML_feat_supercat1.csv\n",
      "-rw-r--r--   1 skenchar  staff  187063 Dec  2 17:51 ML_feat_supercat2.csv\n",
      "-rw-r--r--   1 skenchar  staff   52798 Dec  2 17:51 ML_feat_supercat3.csv\n",
      "-rw-r--r--   1 skenchar  staff   29851 Dec  2 17:51 ML_feat_supercat4.csv\n",
      "-rw-r--r--   1 skenchar  staff  105576 Nov 30 12:13 ML_feature_extractor3.ipynb\n",
      "-rw-r--r--   1 skenchar  staff  115534 Nov 30 20:47 ML_feature_extractor4-Copy1.ipynb\n",
      "-rw-r--r--   1 skenchar  staff  164955 Dec  1 22:31 ML_feature_extractor4.ipynb\n",
      "-rw-r--r--   1 skenchar  staff   23045 Dec  2 09:01 ML_feature_extractor5-Copy1.ipynb\n",
      "-rw-r--r--   1 skenchar  staff   28611 Dec  2 09:27 ML_feature_extractor5.ipynb\n",
      "-rw-r--r--   1 skenchar  staff   26159 Dec  2 17:50 ML_feature_extractor6.ipynb\n",
      "-rw-r--r--   1 skenchar  staff    4102 Nov 29 22:12 Simple Flask REST Calls.ipynb\n",
      "-rw-r--r--   1 skenchar  staff    2331 Nov 29 22:12 dataint.py\n",
      "drwxr-xr-x   8 skenchar  staff     256 Nov 29 22:12 \u001b[34mflask\u001b[m\u001b[m\n",
      "-rw-r--r--   1 skenchar  staff    7789 Nov 29 22:12 solr_wrapper.ipynb\n",
      "-rw-r--r--   1 skenchar  staff    2052 Nov 29 22:12 sql.txt\n",
      "-rw-r--r--   1 skenchar  staff    1077 Nov 29 22:12 wrap.py\n",
      "-rw-r--r--   1 skenchar  staff    8969 Nov 29 22:12 wrappers_local.ipynb\n"
     ]
    }
   ],
   "source": [
    "# save the features into a csv file\n",
    "sdf1a.to_csv('ML_feat_supercat1.csv')\n",
    "sdf2a.to_csv('ML_feat_supercat2.csv')\n",
    "sdf3a.to_csv('ML_feat_supercat3.csv')\n",
    "sdf4a.to_csv('ML_feat_supercat4.csv')\n",
    "!pwd\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
